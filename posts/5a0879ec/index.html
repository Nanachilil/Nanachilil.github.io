<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Pytorch多分类 - Nanachilil的旧仓库</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Nanachilil的旧仓库"><meta name="msapplication-TileImage" content="/img/logo_64.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Nanachilil的旧仓库"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="继二分类 后，通过学习 nn.CrossEntropyLoss() 、softmax() 、argmax() ，我尝试实现了下多分类模型基本工作流程。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏"><meta property="og:type" content="blog"><meta property="og:title" content="Pytorch多分类"><meta property="og:url" content="https://nanachilil.com/posts/5a0879ec/"><meta property="og:site_name" content="Nanachilil的旧仓库"><meta property="og:description" content="继二分类 后，通过学习 nn.CrossEntropyLoss() 、softmax() 、argmax() ，我尝试实现了下多分类模型基本工作流程。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://nanachilil.com/posts/5a0879ec/picture1.png"><meta property="og:image" content="https://nanachilil.com/posts/5a0879ec/image-20240213161744549.png"><meta property="article:published_time" content="2024-02-01T08:13:04.000Z"><meta property="article:modified_time" content="2024-02-25T17:34:44.974Z"><meta property="article:author" content="Nanachilil"><meta property="article:tag" content="分类任务"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="Pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://nanachilil.com/posts/5a0879ec/picture1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://nanachilil.com/posts/5a0879ec/"},"headline":"Pytorch多分类","image":["https://nanachilil.com/posts/5a0879ec/picture1.png","https://nanachilil.com/posts/5a0879ec/image-20240213161744549.png"],"datePublished":"2024-02-01T08:13:04.000Z","dateModified":"2024-02-25T17:34:44.974Z","author":{"@type":"Person","name":"Nanachilil"},"publisher":{"@type":"Organization","name":"Nanachilil的旧仓库","logo":{"@type":"ImageObject","url":"https://nanachilil.com/img/logo.png"}},"description":"继二分类 后，通过学习 nn.CrossEntropyLoss() 、softmax() 、argmax() ，我尝试实现了下多分类模型基本工作流程。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏"}</script><link rel="canonical" href="https://nanachilil.com/posts/5a0879ec/"><link rel="icon" href="/img/logo_64.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Nanachilil的旧仓库" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/guestbook">留言板</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>Pytorch多分类</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-02-01T08:13:04.000Z" title="2024-02-01T08:13:04.000Z">2024-02-01</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> / </span><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch-%E5%A4%9A%E5%88%86%E7%B1%BB/">Pytorch,多分类</a></span><span class="level-item">10 分钟读完 (大约1562个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><div class="content"><html><head></head><body><p>继<a href="https://nanachilil.com/posts/467f8fda/">二分类</a> 后，通过学习 <code>nn.CrossEntropyLoss()</code> 、<code>softmax()</code> 、<code>argmax()</code> ，我尝试实现了下多分类模型基本工作流程。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏</p>
<span id="more"></span>

<p>运行环境：<a target="_blank" rel="noopener" href="https://colab.google/">https://colab.google/</a></p>
<h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><h2 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_blob, y_blob = make_blobs(n_samples = <span class="number">1000</span>, n_features = <span class="number">2</span>, centers = <span class="number">4</span>, cluster_std = <span class="number">1.5</span>, random_state = <span class="number">666</span>)</span><br></pre></td></tr></tbody></table></figure>



<p><strong>make_blobs</strong></p>
<blockquote>
<p>make_blobs 是 Scikit-learn 中用于生成聚类算法测试数据的函数。它能够生成多类别的高斯分布数据集，用于模拟聚类算法的数据集。</p>
<p>n_samples：生成的样本总数，即生成的数据点个数；</p>
<p>n_features：生成的样本的特征数，即维度；</p>
<p>centers：生成的类别数，或者说簇的个数，即数据点围绕几个中心点分布；</p>
<p>random_state：随机数种子，用于控制生成的数据集的随机性，相同的随机数种子会生成相同的数据集；</p>
<p>cluster_std：用于生成聚类数据集时设置聚类的标准差，决定了数据点在每个聚类中的分布紧密程度。标准差越小，数据点越靠近聚类中心，聚类之间的距离越小。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据类型处理</span></span><br><span class="line">X_blob = torch.from_numpy(X_blob).<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line">y_blob = torch.from_numpy(y_blob).<span class="built_in">type</span>(torch.LongTensor) <span class="comment"># LongTensor是一个int64数据类型的值</span></span><br></pre></td></tr></tbody></table></figure>



<h2 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob, y_blob, test_size = <span class="number">0.2</span>, random_state = <span class="number">888</span>)</span><br></pre></td></tr></tbody></table></figure>



<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">plt.scatter(x = X_blob[:,<span class="number">0</span>], y = X_blob[:,<span class="number">1</span>], c = y_blob, cmap = plt.cm.RdYlBu)</span><br><span class="line"></span><br><span class="line">device = <span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span></span><br><span class="line">--&gt;如下图</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/posts/5a0879ec/picture1.png" alt="picture1"></p>
<h1 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlobModel</span>(nn.Module):</span><br><span class="line">  <span class="comment"># hidden_units参数表示隐藏层中神经元的数量，默认值为8。</span></span><br><span class="line">  <span class="comment"># 这个参数决定了神经网络的复杂度和性能。</span></span><br><span class="line">  <span class="comment"># 隐藏层中的神经元数量越多，神经网络就越复杂，可以学习更复杂的模式和特征。</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_features, output_features, hidden_units = <span class="number">8</span></span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.linear_layer_stack = nn.Sequential(</span><br><span class="line">        nn.Linear(in_features = input_features, out_features = hidden_units),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(in_features = hidden_units, out_features = output_features),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="keyword">return</span> self.linear_layer_stack(x)</span><br></pre></td></tr></tbody></table></figure>



<p><strong>hidden_units</strong></p>
<blockquote>
<p>def _<em>init</em>_(self, input_features, output_features, hidden_units = 8):</p>
<p>hidden_units相当于一个中介，进行模型内部的变量传递。</p>
<p>这个参数决定了神经网络的复杂度和性能，隐藏层中的神经元数量越多，神经网络就越复杂，可以学习更复杂的模式和特征。</p>
</blockquote>
<p><strong>self.linear_layer_stack = nn.Sequential()</strong></p>
<blockquote>
<p>将多个nn.Linear() 和 ReLU() 封装在函数内部。省去return时的嵌套处理</p>
</blockquote>
<h2 id="声明模型对象"><a href="#声明模型对象" class="headerlink" title="声明模型对象"></a>声明模型对象</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型和数据，都要保证设备的一致性</span></span><br><span class="line">model_multiclass = BlobModel(input_features = <span class="number">2</span>, output_features = <span class="number">4</span>).to(device)</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">666</span>)</span><br><span class="line">epochs = <span class="number">500</span></span><br><span class="line">X_blob_train, y_blob_train, X_blob_test, y_blob_test = X_blob_train.to(device), y_blob_train.to(device), X_blob_test.to(device), y_blob_test.to(device)</span><br></pre></td></tr></tbody></table></figure>



<h2 id="损失函数和优化器"><a href="#损失函数和优化器" class="headerlink" title="损失函数和优化器"></a>损失函数和优化器</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss() <span class="comment"># 适用于分类的损失</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SGD优化器</span></span><br><span class="line">optimizer = torch.optim.SGD(model_multiclass.parameters(), lr = <span class="number">0.1</span>)</span><br></pre></td></tr></tbody></table></figure>



<p><strong>nn.CrossEntropyLoss()</strong></p>
<blockquote>
<p><code>nn.CrossEntropyLoss()</code> 是PyTorch中用于计算交叉熵损失的函数。[^1]</p>
<p>通常用于训练分类模型时，计算预测类别概率与真实类别标签之间的差异。</p>
<p><code>H(p, q)</code> 值越小，交叉熵也越小，q与p更为接近。</p>
<p>如下图所示：[^2]</p>
<p><img src="/posts/5a0879ec/image-20240213161744549.png" alt="image-20240213161744549"></p>
</blockquote>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">  model_multiclass.train()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 1. forward</span></span><br><span class="line">  y_logits = model_multiclass(X_blob_train)</span><br><span class="line">  y_pred = torch.softmax(y_logits, dim = <span class="number">1</span>).argmax(dim = <span class="number">1</span>)  <span class="comment"># softmax、argmax</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 2.</span></span><br><span class="line">  loss = loss_fn(y_logits, y_blob_train)</span><br><span class="line">  acc = accuracy_fn(y_true = y_blob_train, y_pred = y_pred)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 3</span></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 4</span></span><br><span class="line">  loss.backward()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 5</span></span><br><span class="line">  optimizer.step()</span><br><span class="line"></span><br><span class="line">  model_multiclass.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    test_logits = model_multiclass(X_blob_test)</span><br><span class="line">    test_pred = torch.softmax(test_logits, dim = <span class="number">1</span>).argmax(dim = <span class="number">1</span>)</span><br><span class="line">    test_loss = loss_fn(test_logits, y_blob_test)</span><br><span class="line">    test_acc = accuracy_fn(y_true = y_blob_test, y_pred = test_pred)</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f"Epoch:<span class="subst">{epoch}</span> | Loss:<span class="subst">{loss:<span class="number">.4</span>f}</span>, ACC:<span class="subst">{acc:<span class="number">.2</span>f}</span>% | Test Loss:<span class="subst">{test_loss:<span class="number">.4</span>f}</span>, Test acc:<span class="subst">{test_acc:<span class="number">.2</span>f}</span>%"</span>)</span><br></pre></td></tr></tbody></table></figure>



<p><strong>softmax</strong></p>
<blockquote>
<p><code>Softmax</code> 函数是一种常用的激活函数，通常用于神经网络模型中的多类别分类任务；</p>
<p>它将一个包含数字的向量转换为概率向量，其中每个值的概率与向量中每个值的相对大小成比例。该函数将返回一个 位于范围(0, 1)内 包含概率值的张量 <code>y_pred_probs</code>，其中每一行的和都为 1。</p>
<p>在这个例子中，<code>y_logits</code> 是模型的输出，dim = 1 表示在第二个维度上进行 softmax 计算。</p>
</blockquote>
<p><strong>softmax 与 sigmoid 的区别</strong></p>
<blockquote>
<p>1 输入不同：</p>
<p>​	sigmoid 应用于二分类，输入的是一维数值；而 softmax 应用于多分类，输入的是二维数组</p>
<p>2 输出不同</p>
<p>​	sigmoid 输出一维数组，且数组元素位于 0 ~ 1 范围内；</p>
<p>​	softmax 输出二维数组，数组元素位于 0 ~ 1 范围内，元素含义表示 每个类别的概率，且每行和为1</p>
</blockquote>
<p><strong>argmax</strong></p>
<blockquote>
<p>函数用于返回 张量中指定维度上的最大值的索引 (即哪一类）</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--&gt;</span><br><span class="line">Epoch:<span class="number">492</span> | Loss:<span class="number">0.2597</span>, ACC:<span class="number">86.25</span>% | Test Loss:<span class="number">0.2141</span>, Test acc:<span class="number">91.00</span>%</span><br><span class="line">Epoch:<span class="number">493</span> | Loss:<span class="number">0.2592</span>, ACC:<span class="number">87.50</span>% | Test Loss:<span class="number">0.2080</span>, Test acc:<span class="number">92.50</span>%</span><br><span class="line">Epoch:<span class="number">494</span> | Loss:<span class="number">0.2593</span>, ACC:<span class="number">86.12</span>% | Test Loss:<span class="number">0.2136</span>, Test acc:<span class="number">91.50</span>%</span><br><span class="line">Epoch:<span class="number">495</span> | Loss:<span class="number">0.2589</span>, ACC:<span class="number">87.50</span>% | Test Loss:<span class="number">0.2078</span>, Test acc:<span class="number">92.50</span>%</span><br><span class="line">Epoch:<span class="number">496</span> | Loss:<span class="number">0.2589</span>, ACC:<span class="number">86.50</span>% | Test Loss:<span class="number">0.2132</span>, Test acc:<span class="number">91.50</span>%</span><br><span class="line">Epoch:<span class="number">497</span> | Loss:<span class="number">0.2585</span>, ACC:<span class="number">87.38</span>% | Test Loss:<span class="number">0.2077</span>, Test acc:<span class="number">92.50</span>%</span><br><span class="line">Epoch:<span class="number">498</span> | Loss:<span class="number">0.2585</span>, ACC:<span class="number">86.62</span>% | Test Loss:<span class="number">0.2128</span>, Test acc:<span class="number">91.50</span>%</span><br><span class="line">Epoch:<span class="number">499</span> | Loss:<span class="number">0.2582</span>, ACC:<span class="number">87.38</span>% | Test Loss:<span class="number">0.2075</span>, Test acc:<span class="number">92.50</span>%</span><br></pre></td></tr></tbody></table></figure>

<p><strong>发现 Test acc 达到最高后会下降</strong></p>
<blockquote>
<p>学习率太高，步子迈的太大，在最高值附近来回跳</p>
<p>注意：</p>
<p>​	这里不是过拟合，过拟合是指，模型在训练数据上表现良好，但在测试的数据上表现不佳。过拟合可能会导致模型无法泛化到新的数据集上，因为模型在训练数据集上学习到了噪声而不是信号。</p>
</blockquote>
<h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p>[^1]: 维基百科 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E7%86%B5">交叉熵</a> 相关<br>[^2]: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/98785902">https://zhuanlan.zhihu.com/p/98785902</a> 以及 评论区 <a target="_blank" rel="noopener" href="https://www.zhihu.com/people/333bdf8209fcc3376c0d0ab4453aed63">杨子江</a> 解答</p>
</body></html></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">分类任务, </a><a class="link-muted" rel="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/zhifubao.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/467f8fda/"><span class="level-item">pytorch分类任务</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content twikoo" id="twikoo"></div><script src="https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js"></script><script>twikoo.init({
      envId: 'https://twikoo-pi-five.vercel.app/'
    });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/bin.jpg" alt="Nanachilil"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Nanachilil</p><p class="is-size-6 is-block">Nanachilil的旧仓库</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>WuXi, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">24</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Nanachilil" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://space.bilibili.com/473691769"><i class="fa-brands fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="mail" href="mailto:last1850@outlook.com"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;k=USadAmK9UBNWzBfkIB0VQIjJLr1tRkpM&amp;authKey=xVKjTKf%2FE9NQGBgPRM27qMq7JJ2HpbXvLX0m3AZUvH9naIfO4qpZbcojsKrN%2BYH4&amp;noverify=0&amp;group_code=876827316"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#数据准备"><span class="level-left"><span class="level-item">1</span><span class="level-item">数据准备</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#准备数据集"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">准备数据集</span></span></a></li><li><a class="level is-mobile" href="#划分数据集"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">划分数据集</span></span></a></li><li><a class="level is-mobile" href="#可视化"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">可视化</span></span></a></li></ul></li><li><a class="level is-mobile" href="#建立模型"><span class="level-left"><span class="level-item">2</span><span class="level-item">建立模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#模型"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">模型</span></span></a></li><li><a class="level is-mobile" href="#声明模型对象"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">声明模型对象</span></span></a></li><li><a class="level is-mobile" href="#损失函数和优化器"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">损失函数和优化器</span></span></a></li></ul></li><li><a class="level is-mobile" href="#训练模型"><span class="level-left"><span class="level-item">3</span><span class="level-item">训练模型</span></span></a></li><li><a class="level is-mobile" href="#reference"><span class="level-left"><span class="level-item">4</span><span class="level-item">reference</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/hexo/"><span class="level-start"><span class="level-item">hexo</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/hexo/icarus/"><span class="level-start"><span class="level-item">icarus</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/hexo/twikoo/"><span class="level-start"><span class="level-item">twikoo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/hexo/%E6%8A%A5%E9%94%99/"><span class="level-start"><span class="level-item">报错</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch-%E5%A4%9A%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">Pytorch,多分类</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"><span class="level-start"><span class="level-item">二分查找</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E5%8D%95%E9%93%BE%E8%A1%A8/"><span class="level-start"><span class="level-item">单链表</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E5%8D%95%E9%93%BE%E8%A1%A8/%E6%A0%88/"><span class="level-start"><span class="level-item">栈</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E6%A0%88/"><span class="level-start"><span class="level-item">栈</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spawn-failed/"><span class="tag">Spawn_failed</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/icarus/"><span class="tag">icarus</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/twikoo/"><span class="tag">twikoo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%8D%E5%B8%A6%E5%A4%B4%E7%BB%93%E7%82%B9/"><span class="tag">不带头结点</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%83%E7%B4%A0%E9%80%92%E5%A2%9E/"><span class="tag">元素递增</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%B1%E4%BA%AB%E6%A0%88/"><span class="tag">共享栈</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"><span class="tag">分类任务</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%A4%E6%96%AD%E5%AF%B9%E7%A7%B0%E6%80%A7/"><span class="tag">判断对称性</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E9%93%BE%E8%A1%A8/"><span class="tag">单链表</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B8%A6%E5%A4%B4%E7%BB%93%E7%82%B9/"><span class="tag">带头结点</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8C%89%E5%80%BC%E5%88%A0%E9%99%A4/"><span class="tag">按值删除</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%E5%8A%9F%E8%83%BD/"><span class="tag">插入图片功能</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%BF%97/"><span class="tag">日志</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%80%E5%B0%8F%E5%80%BC/"><span class="tag">最小值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9F%A5%E6%89%BE/"><span class="tag">查找</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A0%88/"><span class="tag">栈</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E4%BD%8E/"><span class="tag">空间复杂度低</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="tag">线性回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%86%E5%BA%8F/"><span class="tag">逆序</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%92%E5%BD%92/"><span class="tag">递归</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%AB%98%E6%95%88%E7%AE%97%E6%B3%95/"><span class="tag">高效算法</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Nanachilil的旧仓库" height="28"></a><p class="is-size-7"><span>&copy; 2024 Nanachilil</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-right",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/custom.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>