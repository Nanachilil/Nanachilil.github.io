<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>pytorch分类任务 - Nanachilil的旧仓库</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Nanachilil的旧仓库"><meta name="msapplication-TileImage" content="/img/logo_64.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Nanachilil的旧仓库"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="学习二分类问题的模型，熟悉逻辑损失函数、pandas.DataFrame()的基础应用。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏"><meta property="og:type" content="blog"><meta property="og:title" content="pytorch分类任务"><meta property="og:url" content="https://nanachilil.com/posts/467f8fda/"><meta property="og:site_name" content="Nanachilil的旧仓库"><meta property="og:description" content="学习二分类问题的模型，熟悉逻辑损失函数、pandas.DataFrame()的基础应用。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://nanachilil.com/posts/467f8fda/image-20240212150355179.png"><meta property="article:published_time" content="2024-01-21T08:13:04.000Z"><meta property="article:modified_time" content="2024-02-25T17:34:39.581Z"><meta property="article:author" content="Nanachilil"><meta property="article:tag" content="分类任务"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="Pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://nanachilil.com/posts/467f8fda/image-20240212150355179.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://nanachilil.com/posts/467f8fda/"},"headline":"pytorch分类任务","image":["https://nanachilil.com/posts/467f8fda/image-20240212150355179.png"],"datePublished":"2024-01-21T08:13:04.000Z","dateModified":"2024-02-25T17:34:39.581Z","author":{"@type":"Person","name":"Nanachilil"},"publisher":{"@type":"Organization","name":"Nanachilil的旧仓库","logo":{"@type":"ImageObject","url":"https://nanachilil.com/img/logo.png"}},"description":"学习二分类问题的模型，熟悉逻辑损失函数、pandas.DataFrame()的基础应用。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏"}</script><link rel="canonical" href="https://nanachilil.com/posts/467f8fda/"><link rel="icon" href="/img/logo_64.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Nanachilil的旧仓库" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/guestbook">留言板</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>pytorch分类任务</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-01-21T08:13:04.000Z" title="2024-01-21T08:13:04.000Z">2024-01-21</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> / </span><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch/">Pytorch</a></span><span class="level-item">16 分钟读完 (大约2413个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><div class="content"><html><head></head><body><p>学习二分类问题的模型，熟悉逻辑损失函数、pandas.DataFrame()的基础应用。本博文主要用于整理个人的知识框架，希望也能帮到大家。如有不足，欢迎留言。🙏</p>
<span id="more"></span>

<h1 id="Pytorch分类任务"><a href="#Pytorch分类任务" class="headerlink" title="Pytorch分类任务"></a>Pytorch分类任务</h1><p>运行环境：<a target="_blank" rel="noopener" href="https://colab.google/">https://colab.google/</a></p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a><strong>数据准备</strong></h2><h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">make_circles 是 scikit-learn 库中的 sklearn.datasets 模块中的一个函数。</span></span><br><span class="line"><span class="string">它用于生成一个带有圆形决策边界的玩具数据集。这个函数对于测试和可视化处理非线性可分数据的算法非常有用。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">n_samples = <span class="number">1000</span></span><br><span class="line">X, y =make_circles(n_samples, noise = <span class="number">0.03</span>, random_state = <span class="number">666</span>)</span><br><span class="line"><span class="comment"># make_circles生成的数据集通常用于二分类问题,类别标签通常是 0 或 1。生成的数据集中的每个样本都属于两个类别中的一个</span></span><br><span class="line"><span class="comment"># y 的标签是根据每个样本点是否在大圆圈内来确定的，如果在大圆圈内则标签为 1，否则标签为 0。</span></span><br><span class="line"></span><br><span class="line">X.shape, y.shape <span class="comment"># X.shape: 这将返回一个元组，描述了X数组的维度</span></span><br><span class="line"><span class="comment"># （1000，2）二维数组，1000为行数，2为列数</span></span><br><span class="line"><span class="comment"># （1000，） 一位数组，即label</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">type</span>(X), <span class="built_in">type</span>(y)</span><br><span class="line">--&gt; (numpy.ndarray, numpy.ndarray)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据类型的转换</span></span><br><span class="line"><span class="comment"># 为什么 要把numpy转为tensoar？</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统一的计算环境</span></span><br><span class="line"><span class="comment"># 动态图 vs 静态图</span></span><br><span class="line"><span class="comment"># 内存管理</span></span><br><span class="line"><span class="comment"># GPU加速</span></span><br><span class="line"><span class="comment"># 自动求导和优化器</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">X = torch.from_numpy(X)</span><br><span class="line">y = torch.from_numpy(y)</span><br><span class="line"></span><br><span class="line">X = X.<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line">y = y.<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">在将 NumPy 数组转换为 PyTorch 张量时，如果没有指定数据类型，PyTorch 将会使用与原始数组相同的数据类型。因此，如果原始的 NumPy 数组中的数据类型是 float32 或 float64，那么转换后的 PyTorch 张量的数据类型也会是相应的 torch.float32 或 torch.float64。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">我们需要明确指定数据类型，以确保数据类型与模型和计算设备（如 GPU）的要求相匹配</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">torch.float 实际上是 torch.float32 的别名。</span></span><br><span class="line"><span class="string">使用 32 位的内存空间来表示浮点数，具有较高的计算性能，通常在深度学习中被广泛使用。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>



<h3 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">666</span>)</span><br><span class="line"><span class="comment"># 随机20%划分完成后，X_train 和 y_train 分别包含训练集的特征数据和标签数据，X_test 和 y_test 分别包含测试集的特征数据和标签数据。</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>



<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><h4 id="pandas-DataFrame"><a href="#pandas-DataFrame" class="headerlink" title="pandas.DataFrame"></a>pandas.DataFrame</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># 用于引入DataFrame</span></span><br><span class="line">circles = pd.DataFrame({<span class="string">"X1"</span>:X[:,<span class="number">0</span>], <span class="string">"X2"</span>:X[:,<span class="number">1</span>], <span class="string">"label"</span>:y})</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">DataFrame 是 Pandas 中最重要的数据结构之一，它类似于电子表格或数据库表格。</span></span><br><span class="line"><span class="string">DataFrame 是一个二维标记数据结构，可以容纳多种类型的数据，并且每一列都可以有不同的数据类型。</span></span><br><span class="line"><span class="string">DataFrame 允许你以一种类似于 SQL 或 Excel 的方式轻松地对数据进行操作、筛选、分组和汇总。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">X[:,0] 表示取 X 中所有行的第一个特征，即将所有样本的第一个特征存储到 X1 列中。</span></span><br><span class="line"><span class="string">X[:,1] 表示取 X 中所有行的第二个特征，即将所有样本的第二个特征存储到 X2 列中。</span></span><br><span class="line"><span class="string">y 则表示样本的标签，将其存储到 label 列中。</span></span><br><span class="line"><span class="string">最终生成的 DataFrame circles 包含了两个特征列 X1 和 X2，以及一个标签列 label，用来存储每个样本的特征和标签信息。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">circles.head(<span class="number">10</span>)</span><br><span class="line">--&gt;如下表</span><br></pre></td></tr></tbody></table></figure>

<table>
<thead>
<tr>
<th>index</th>
<th>X1</th>
<th>X2</th>
<th>label</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.5232532787040866</td>
<td>0.6130051138010815</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0.5590261056027346</td>
<td>-0.7938079756641505</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>0.07279950491964153</td>
<td>1.0158009611913412</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0.643975455169496</td>
<td>0.4792458217715751</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>0.7277505858717157</td>
<td>-0.3306116318780561</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>0.8114212398289349</td>
<td>-0.5947803838171337</td>
<td>0</td>
</tr>
<tr>
<td>6</td>
<td>-0.9228566785254152</td>
<td>-0.31323880736337917</td>
<td>0</td>
</tr>
<tr>
<td>7</td>
<td>0.8211164440168314</td>
<td>-0.52126486439117</td>
<td>0</td>
</tr>
<tr>
<td>8</td>
<td>-0.862636456661466</td>
<td>0.052975218510684215</td>
<td>1</td>
</tr>
<tr>
<td>9</td>
<td>-0.7868902607268425</td>
<td>0.10441672781411158</td>
<td>1</td>
</tr>
</tbody></table>
<h4 id="matplotlib-pyplot"><a href="#matplotlib-pyplot" class="headerlink" title="matplotlib.pyplot"></a>matplotlib.pyplot</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.scatter(x = X[:,<span class="number">0</span>], y = X[:,<span class="number">1</span>], c = y, cmap = plt.cm.RdYlBu)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这段代码使用 Matplotlib 库创建了一个散点图，</span></span><br><span class="line"><span class="string">其中 x 轴表示数据集中的第一个特征（X1），</span></span><br><span class="line"><span class="string">y 轴表示数据集中的第二个特征（X2），并根据标签（y）对点的颜色进行着色。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">plt.scatter() 函数用于创建散点图。</span></span><br><span class="line"><span class="string">x = X[:,0] 指定 x 轴的值为数据集中所有样本的第一个特征。</span></span><br><span class="line"><span class="string">y = X[:,1] 指定 y 轴的值为数据集中所有样本的第二个特征。</span></span><br><span class="line"><span class="string">c = y 指定散点的颜色根据标签 y 的值来确定。注意，此处的y表示label的y，而不是数据集的第二个特征</span></span><br><span class="line"><span class="string">cmap = plt.cm.RdYlBu 指定了使用的颜色映射，这里使用了红黄蓝的颜色映射。</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></tbody></table></figure>



<p><img src="/posts/467f8fda/image-20240212150355179.png" alt="image-20240212150355179"></p>
<h2 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a><strong>建立模型</strong></h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保设备一致性</span></span><br><span class="line">device = <span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CircleModelV0</span>(nn.Module):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="comment"># nn.Linear 是 PyTorch 中的一个类，用于创建线性（全连接）层。它的作用是将输入的数据进行线性变换</span></span><br><span class="line">    <span class="comment"># 这种映射是复杂的的变换和映射。每个线性层都引入了一组可学习的权重参数，这些参数会在训练过程中进行调整，以使模型能够更好地拟合训练数据并进行预测。而 不是将输入的元素简单的重新按维度组合。</span></span><br><span class="line">    self.layer_1 = nn.Linear(in_features = <span class="number">2</span>, out_features = <span class="number">5</span>) <span class="comment"># 这个线性层将输入的特征空间维度从 2 维映射到了 5 维。</span></span><br><span class="line">    self.layer_2 = nn.Linear(in_features = <span class="number">5</span>, out_features = <span class="number">1</span>)</span><br><span class="line">    self.relu = nn.ReLU() <span class="comment"># 激活函数引入非线性属性，从而增加神经网络的表达能力和学习能力。</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment"># forward()定义模型的前向传播过程</span></span><br><span class="line">    <span class="keyword">return</span> self.layer_2(self.relu(self.layer_1(x)))</span><br></pre></td></tr></tbody></table></figure>



<h3 id="声明模型对象"><a href="#声明模型对象" class="headerlink" title="声明模型对象"></a>声明模型对象</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_0 = CircleModelV0().to(device)</span><br></pre></td></tr></tbody></table></figure>



<h3 id="分类函数的损失函数如何来定"><a href="#分类函数的损失函数如何来定" class="headerlink" title="分类函数的损失函数如何来定"></a>分类函数的损失函数如何来定</h3><p><strong>思考：如何把预测值映射为 0 还是 1？</strong></p>
<blockquote>
<p>使用sigmoid函数，然后将 1 / (1 + e^-x) 与0.5来比，使用torch.round()函数四舍五入。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># logistic函数，即sigmoid函数，把实数压缩到0~1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.nn.BCELoss()  没有经过logistic回归层</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Logistic回归是一种用于解决二分类问题的线性模型，通常用于估计样本属于某一类的概率。</span></span><br><span class="line"><span class="string">Logistic回归可以被视为一个单层的神经网络，其输出通过一个sigmoid函数进行转换，将线性变换的结果压缩到 (0, 1) 区间，表示样本属于某一类的概率。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">在PyTorch中，可以使用 nn.Linear 创建一个全连接层，然后通过 nn.Sigmoid 激活函数将线性变换的结果转换为 (0, 1) 区间的概率值。</span></span><br><span class="line"><span class="string">这样的组合通常被称为Logistic回归层，用于二分类问题的预测。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">例如，在PyTorch中，可以如下定义一个简单的Logistic回归层：</span></span><br><span class="line"><span class="string">import torch</span></span><br><span class="line"><span class="string">import torch.nn as nn</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">class LogisticRegression(nn.Module):</span></span><br><span class="line"><span class="string">    def __init__(self, input_dim):</span></span><br><span class="line"><span class="string">        super(LogisticRegression, self).__init__()</span></span><br><span class="line"><span class="string">        self.linear = nn.Linear(input_dim, 1)</span></span><br><span class="line"><span class="string">        self.sigmoid = nn.Sigmoid()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def forward(self, x):</span></span><br><span class="line"><span class="string">        out = self.linear(x)</span></span><br><span class="line"><span class="string">        out = self.sigmoid(out)</span></span><br><span class="line"><span class="string">        return out</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数定义</span></span><br><span class="line">loss_fn = torch.nn.BCEWithLogitsLoss() <span class="comment"># 经过logistic回归层</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">torch.nn.BCEWithLogitsLoss()这个损失函数结合了 Sigmoid 激活函数和二元交叉熵损失函数，同时计算了两者的结果</span></span><br><span class="line"><span class="string">使用 BCEWithLogitsLoss 可以简化代码，提高计算效率，尤其适用于二分类问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import torch</span></span><br><span class="line"><span class="string">import torch.nn as nn</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 创建模型</span></span><br><span class="line"><span class="string">model = YourModel()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 定义损失函数</span></span><br><span class="line"><span class="string">criterion = nn.BCEWithLogitsLoss()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 假设预测结果和真实标签已经准备好</span></span><br><span class="line"><span class="string">outputs = model(inputs)</span></span><br><span class="line"><span class="string">loss = criterion(outputs, targets)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 清零梯度</span></span><br><span class="line"><span class="string">optimizer.zero_grad()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 反向传播</span></span><br><span class="line"><span class="string">loss.backward()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 更新参数</span></span><br><span class="line"><span class="string">optimizer.step()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(params = model_0.parameters(), lr = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<h3 id="辅助观察函数声明"><a href="#辅助观察函数声明" class="headerlink" title="辅助观察函数声明"></a>辅助观察函数声明</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于计算 预测结果的一致程度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy_fn</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">  correct = torch.<span class="built_in">sum</span>(y_true == y_pred).item()</span><br><span class="line"></span><br><span class="line">  acc = correct / <span class="built_in">len</span>(y_true) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> acc</span><br></pre></td></tr></tbody></table></figure>



<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">666</span>)</span><br><span class="line">epochs = <span class="number">185</span></span><br><span class="line">X_train, y_train = X_train.to(device), y_train.to(device)</span><br><span class="line">X_test, y_test = X_test.to(device), y_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">  model_0.train() <span class="comment"># 将模型设置为训练模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># squeeze()移除单维度，方便比较</span></span><br><span class="line"><span class="comment"># 将 (1, n) 或 (n, 1) 的张量，变为 (n,) 的一维张量。有些函数可能要求输入张量的形状必须是一维的</span></span><br><span class="line"><span class="comment"># 使用 squeeze() 可以使得代码更加简洁和清晰，避免了一些不必要的单维度，提高了代码的可读性和可维护性。</span></span><br><span class="line">  y_logits = model_0(X_train).squeeze() </span><br><span class="line">  y_pred = torch.<span class="built_in">round</span>(torch.sigmoid(y_logits)) <span class="comment"># torch.sigmoid() 将y_logits变为 0 ~ 1 ，torch.round() 进行四舍五入</span></span><br><span class="line">  loss = loss_fn(y_logits, y_train) <span class="comment"># 用去除维度后的y_logits与y_train计算损失函数</span></span><br><span class="line">  acc = accuracy_fn(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line">  loss.backward()</span><br><span class="line">  optimizer.step()</span><br><span class="line"></span><br><span class="line">  model_0.<span class="built_in">eval</span>()</span><br><span class="line">  <span class="comment"># model_0.eval()和torch.inference_mode()的区别：</span></span><br><span class="line">  <span class="comment"># 都用于将模型设置为评估模式（inference mode），但它们有一些区别。</span></span><br><span class="line">  <span class="comment"># 总的来说，model_0.eval() 更适合在模型级别进行模式切换，而 torch.inference_mode() 更适合在全局级别临时切换模式。</span></span><br><span class="line">    </span><br><span class="line">  <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    test_logits = model_0(X_test).squeeze()</span><br><span class="line">    test_pred = torch.<span class="built_in">round</span>(torch.sigmoid(test_logits))</span><br><span class="line"></span><br><span class="line">    test_loss = loss_fn(test_logits, y_test)</span><br><span class="line">    test_acc = accuracy_fn(y_test, test_pred)</span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f"<span class="subst">{epoch}</span> | Loss:<span class="subst">{loss}</span> | acc:<span class="subst">{acc}</span> | Test Loss:<span class="subst">{test_loss}</span> | Test Acc:<span class="subst">{test_acc}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>



<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">--&gt;</span><br><span class="line">...</span><br><span class="line"><span class="number">168</span> | Loss:<span class="number">0.5972417593002319</span> | acc:<span class="number">72.125</span> | Test Loss:<span class="number">0.601545512676239</span> | Test Acc:<span class="number">71.5</span></span><br><span class="line"><span class="number">169</span> | Loss:<span class="number">0.595664918422699</span> | acc:<span class="number">72.5</span> | Test Loss:<span class="number">0.6001173257827759</span> | Test Acc:<span class="number">73.0</span></span><br><span class="line"><span class="number">170</span> | Loss:<span class="number">0.5940487384796143</span> | acc:<span class="number">73.0</span> | Test Loss:<span class="number">0.5980546474456787</span> | Test Acc:<span class="number">72.5</span></span><br><span class="line"><span class="number">171</span> | Loss:<span class="number">0.5923799276351929</span> | acc:<span class="number">73.5</span> | Test Loss:<span class="number">0.5966604948043823</span> | Test Acc:<span class="number">73.0</span></span><br><span class="line"><span class="number">172</span> | Loss:<span class="number">0.5906763076782227</span> | acc:<span class="number">74.0</span> | Test Loss:<span class="number">0.5944149494171143</span> | Test Acc:<span class="number">74.0</span></span><br><span class="line"><span class="number">173</span> | Loss:<span class="number">0.5889647006988525</span> | acc:<span class="number">74.375</span> | Test Loss:<span class="number">0.593086302280426</span> | Test Acc:<span class="number">75.0</span></span><br><span class="line"><span class="number">174</span> | Loss:<span class="number">0.5872295498847961</span> | acc:<span class="number">74.375</span> | Test Loss:<span class="number">0.5907705426216125</span> | Test Acc:<span class="number">74.0</span></span><br><span class="line"><span class="number">175</span> | Loss:<span class="number">0.5854421854019165</span> | acc:<span class="number">74.625</span> | Test Loss:<span class="number">0.5894856452941895</span> | Test Acc:<span class="number">76.0</span></span><br><span class="line"><span class="number">176</span> | Loss:<span class="number">0.5837037563323975</span> | acc:<span class="number">75.875</span> | Test Loss:<span class="number">0.5870495438575745</span> | Test Acc:<span class="number">75.5</span></span><br><span class="line"><span class="number">177</span> | Loss:<span class="number">0.5819454789161682</span> | acc:<span class="number">75.25</span> | Test Loss:<span class="number">0.5859463214874268</span> | Test Acc:<span class="number">76.5</span></span><br><span class="line"><span class="number">178</span> | Loss:<span class="number">0.580162763595581</span> | acc:<span class="number">76.25</span> | Test Loss:<span class="number">0.5832081437110901</span> | Test Acc:<span class="number">76.0</span></span><br><span class="line"><span class="number">179</span> | Loss:<span class="number">0.5783393979072571</span> | acc:<span class="number">76.375</span> | Test Loss:<span class="number">0.5823167562484741</span> | Test Acc:<span class="number">77.5</span></span><br><span class="line"><span class="number">180</span> | Loss:<span class="number">0.5764892101287842</span> | acc:<span class="number">77.625</span> | Test Loss:<span class="number">0.5792547464370728</span> | Test Acc:<span class="number">77.0</span></span><br><span class="line"><span class="number">181</span> | Loss:<span class="number">0.5746139883995056</span> | acc:<span class="number">76.75</span> | Test Loss:<span class="number">0.5787341594696045</span> | Test Acc:<span class="number">77.5</span></span><br><span class="line"><span class="number">182</span> | Loss:<span class="number">0.5727413296699524</span> | acc:<span class="number">78.5</span> | Test Loss:<span class="number">0.5753249526023865</span> | Test Acc:<span class="number">77.0</span></span><br><span class="line"><span class="number">183</span> | Loss:<span class="number">0.5708712339401245</span> | acc:<span class="number">77.25</span> | Test Loss:<span class="number">0.5753326416015625</span> | Test Acc:<span class="number">80.5</span></span><br><span class="line"><span class="number">184</span> | Loss:<span class="number">0.5689650177955627</span> | acc:<span class="number">81.875</span> | Test Loss:<span class="number">0.5713624954223633</span> | Test Acc:<span class="number">80.0</span></span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure>



</body></html></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">分类任务, </a><a class="link-muted" rel="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/zhifubao.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/5a0879ec/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Pytorch多分类</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/e8eb0481/"><span class="level-item">二分查找</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content twikoo" id="twikoo"></div><script src="https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js"></script><script>twikoo.init({
      envId: 'https://twikoo-pi-five.vercel.app/'
    });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/bin.jpg" alt="Nanachilil"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Nanachilil</p><p class="is-size-6 is-block">Nanachilil的旧仓库</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>WuXi, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">13</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">26</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Nanachilil" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://space.bilibili.com/473691769"><i class="fa-brands fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="mail" href="mailto:last1850@outlook.com"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;k=USadAmK9UBNWzBfkIB0VQIjJLr1tRkpM&amp;authKey=xVKjTKf%2FE9NQGBgPRM27qMq7JJ2HpbXvLX0m3AZUvH9naIfO4qpZbcojsKrN%2BYH4&amp;noverify=0&amp;group_code=876827316"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Pytorch分类任务"><span class="level-left"><span class="level-item">1</span><span class="level-item">Pytorch分类任务</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#数据准备"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">数据准备</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#准备数据集"><span class="level-left"><span class="level-item">1.1.1</span><span class="level-item">准备数据集</span></span></a></li><li><a class="level is-mobile" href="#划分数据集"><span class="level-left"><span class="level-item">1.1.2</span><span class="level-item">划分数据集</span></span></a></li><li><a class="level is-mobile" href="#可视化"><span class="level-left"><span class="level-item">1.1.3</span><span class="level-item">可视化</span></span></a></li></ul></li><li><a class="level is-mobile" href="#建立模型"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">建立模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#模型"><span class="level-left"><span class="level-item">1.2.1</span><span class="level-item">模型</span></span></a></li><li><a class="level is-mobile" href="#声明模型对象"><span class="level-left"><span class="level-item">1.2.2</span><span class="level-item">声明模型对象</span></span></a></li><li><a class="level is-mobile" href="#分类函数的损失函数如何来定"><span class="level-left"><span class="level-item">1.2.3</span><span class="level-item">分类函数的损失函数如何来定</span></span></a></li><li><a class="level is-mobile" href="#辅助观察函数声明"><span class="level-left"><span class="level-item">1.2.4</span><span class="level-item">辅助观察函数声明</span></span></a></li></ul></li><li><a class="level is-mobile" href="#训练模型"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">训练模型</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/GVim/"><span class="level-start"><span class="level-item">GVim</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/hexo/"><span class="level-start"><span class="level-item">hexo</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/hexo/icarus/"><span class="level-start"><span class="level-item">icarus</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/hexo/twikoo/"><span class="level-start"><span class="level-item">twikoo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/hexo/%E6%8A%A5%E9%94%99/"><span class="level-start"><span class="level-item">报错</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Pytorch-%E5%A4%9A%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">Pytorch,多分类</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"><span class="level-start"><span class="level-item">二分查找</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E5%8D%95%E9%93%BE%E8%A1%A8/"><span class="level-start"><span class="level-item">单链表</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E5%8D%95%E9%93%BE%E8%A1%A8/%E6%A0%88/"><span class="level-start"><span class="level-item">栈</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/%E6%A0%88/"><span class="level-start"><span class="level-item">栈</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spawn-failed/"><span class="tag">Spawn_failed</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/gvim/"><span class="tag">gvim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/icarus/"><span class="tag">icarus</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/twikoo/"><span class="tag">twikoo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%8D%E5%B8%A6%E5%A4%B4%E7%BB%93%E7%82%B9/"><span class="tag">不带头结点</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%83%E7%B4%A0%E9%80%92%E5%A2%9E/"><span class="tag">元素递增</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%B1%E4%BA%AB%E6%A0%88/"><span class="tag">共享栈</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"><span class="tag">分类任务</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%A4%E6%96%AD%E5%AF%B9%E7%A7%B0%E6%80%A7/"><span class="tag">判断对称性</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E9%93%BE%E8%A1%A8/"><span class="tag">单链表</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B8%A6%E5%A4%B4%E7%BB%93%E7%82%B9/"><span class="tag">带头结点</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8C%89%E5%80%BC%E5%88%A0%E9%99%A4/"><span class="tag">按值删除</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%E5%8A%9F%E8%83%BD/"><span class="tag">插入图片功能</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%BF%97/"><span class="tag">日志</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%80%E5%B0%8F%E5%80%BC/"><span class="tag">最小值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9F%A5%E6%89%BE/"><span class="tag">查找</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A0%88/"><span class="tag">栈</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E4%BD%8E/"><span class="tag">空间复杂度低</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="tag">线性回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%86%E5%BA%8F/"><span class="tag">逆序</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%92%E5%BD%92/"><span class="tag">递归</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/"><span class="tag">配置相关</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%AB%98%E6%95%88%E7%AE%97%E6%B3%95/"><span class="tag">高效算法</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Nanachilil的旧仓库" height="28"></a><p class="is-size-7"><span>&copy; 2024 Nanachilil</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-right",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/custom.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>